## 堆
python中内置了堆算法,**堆**其实就是一个完全二叉树,其满足对于堆的元素来说,都有**heap[k] <= heap[2*k+1]** 和 **heap[k] <= heap[2*k+2]**(最小堆).按照root节点是否为最大/小值,可以分为最大/小堆。

## 利用heap实现优先队列，
因为最小堆的root始终是最小的元素,所以利用这个特性，可是实现优先队列,优先级越小的越先处理.但有一个问题:如果有相同优先级的元素,需要保证按照他们的入队顺序入队取出?解决这个方法可以通过对队列里的元素进行添加多个比较属性来解决,比如将元素封装成一个三元组:**[priority, count, task]**,即当优先级**priority**相同时，再比较第二个参数**count**.下面看一个官方的例子:       
```python

pq = []                         # list of entries arranged in a heap
entry_finder = {}               # mapping of tasks to entries
REMOVED = '<removed-task>'      # placeholder for a removed task
counter = itertools.count()     # unique sequence count

def add_task(task, priority=0):
    'Add a new task or update the priority of an existing task'
    if task in entry_finder:
        remove_task(task)
    count = next(counter) # count+1 优先级相同时，比较count
    entry = [priority, count, task]
    entry_finder[task] = entry
    heappush(pq, entry) # 在堆pq中添加元素entry,先比较priority,在比较count

def remove_task(task):
    ## 从task map中移除，并把把移除的entry中task设置为remove状态
    'Mark an existing task as REMOVED.  Raise KeyError if not found.'
    entry = entry_finder.pop(task)
    entry[-1] = REMOVED # 

def pop_task():
    'Remove and return the lowest priority task. Raise KeyError if empty.'
    while pq:
        priority, count, task = heappop(pq) # 弹出
        if task is not REMOVED:
            del entry_finder[task]
            return task
    raise KeyError('pop from an empty priority queue')

```

### Celery定时任务scheduler中的优先队列
celery中实现定时任务调度的调度器也是通过python内置的heap来实现优先队列的,直接看源码:

```python
class Scheduler:
    """Scheduler for periodic tasks.

    The :program:`celery beat` program may instantiate this class
    multiple times for introspection purposes, but then with the
    ``lazy`` argument set.  It's important for subclasses to
    be idempotent when this argument is set.

    Arguments:
        schedule (~celery.schedules.schedule): see :attr:`schedule`.
        max_interval (int): see :attr:`max_interval`.
        lazy (bool): Don't set up the schedule.
    """

    Entry = ScheduleEntry

    #: The schedule dict/shelve.
    schedule = None

    #: Maximum time to sleep between re-checking the schedule.
    max_interval = DEFAULT_MAX_INTERVAL

    #: How often to sync the schedule (3 minutes by default)
    sync_every = 3 * 60

    #: How many tasks can be called before a sync is forced.
    sync_every_tasks = None

    _last_sync = None
    _tasks_since_sync = 0

    logger = logger  # compat

    def __init__(self, app, schedule=None, max_interval=None,
                 Producer=None, lazy=False, sync_every_tasks=None, **kwargs):
        self.app = app
        print(self.app.send_task)
        self.data = maybe_evaluate({} if schedule is None else schedule)
        self.max_interval = (max_interval or
                            app.conf.beat_max_loop_interval or
                            self.max_interval)
        self.Producer = Producer or app.amqp.Producer
        self._heap = None
        self.old_schedulers = None
        self.sync_every_tasks = (
            app.conf.beat_sync_every if sync_every_tasks is None
            else sync_every_tasks)
        if not lazy:
            self.setup_schedule()

 
    def adjust(self, n, drift=-0.010):
        if n and n > 0:
            return n + drift
        return n

    def is_due(self, entry):# 是否已经进入等待被调度的状态？
        return entry.is_due()


    def populate_heap(self, event_t=event_t, heapify=heapq.heapify):
        """Populate the heap with the data contained in the schedule."""
        ## 把schedule中的任务生成一个堆结构
        priority = 5 #优先级？
        self._heap = []
        for entry in self.schedule.values():
            is_due, next_call_delay = entry.is_due() 

            self._heap.append(event_t(
                self._when(
                    entry,
                    0 if is_due else next_call_delay
                ) or 0,
                priority, entry
            ))
        # 把 _heap列表生成对应的heapify结构
        heapify(self._heap)

    # pylint disable=redefined-outer-name
    def tick(self, event_t=event_t, min=min, heappop=heapq.heappop,
            heappush=heapq.heappush):
        """Run a tick - one iteration of the scheduler.

        Executes one due task per call.

        Returns:
            float: preferred delay in seconds for next call.
        """
        adjust = self.adjust
        max_interval = self.max_interval

        ### 运行TICK的时候，判断下如果还没生成对用的heap.则生成
        if (self._heap is None or
                not self.schedules_equal(self.old_schedulers, self.schedule)):
            self.old_schedulers = copy.copy(self.schedule)
            self.populate_heap()

        H = self._heap

        if not H: # 如果当前没有要执行的定时任务，则返回最大的tick间隔
            return max_interval
        # ('event_t', ('time', 'priority', 'entry'))
        event = H[0]  # 获取堆中的第一个元素，不弹出
        entry = event[2] # 获取对应的modelEntry
        is_due, next_time_to_run = self.is_due(entry) # 当前是否应该运行该task.以及下次的运行时间
        if is_due:
            verify = heappop(H) # 弹出并返回 heap 的最小的元素，保持堆的不变性。这里还是返回 H[0],这里应该是防止 is_due 期间有新的任务插入？
            if verify is event: 
                next_entry = self.reserve(entry) # 获取entry的下次执行时间
                self.apply_entry(entry, producer=self.producer) # 
                heappush(H, event_t(self._when(next_entry, next_time_to_run),
                                    event[1], next_entry)) #把当前的任务执行的时间改为下次执行时间。重新PUSH进去
                return 0 # 不用去执行同步task，此次修改不用去做数据库同步
            else:
                heappush(H, verify)
                return min(verify[0], max_interval) # 返回下次要提交任务的时间，即为堆中 min(最块的执行的任务的时间戳,最大tick时间间隔)
        return min(adjust(next_time_to_run) or max_interval, max_interval)

    def should_sync(self):
        ## 判断是否需要做一次同步
        return (
            (not self._last_sync or
             (time.monotonic() - self._last_sync) > self.sync_every) or
            (self.sync_every_tasks and
             self._tasks_since_sync >= self.sync_every_tasks)
        )

    def reserve(self, entry):
        new_entry = self.schedule[entry.name] = next(entry)
        return new_entry

    def apply_async(self, entry, producer=None, advance=True, **kwargs):
        # Update time-stamps and run counts before we actually execute,
        # so we have that done if an exception is raised (doesn't schedule
        # forever.)
        entry = self.reserve(entry) if advance else entry
        task = self.app.tasks.get(entry.task)

        try:
            entry_args = _evaluate_entry_args(entry.args)
            entry_kwargs = _evaluate_entry_kwargs(entry.kwargs)
            if task:
                ## 运行task
                return task.apply_async(entry_args, entry_kwargs,
                                        producer=producer,
                                        **entry.options)
            else:
                ## 新增task
                return self.send_task(entry.task, entry_args, entry_kwargs,
                                      producer=producer,
                                      **entry.options) # 新增一个task
        except Exception as exc:  # pylint: disable=broad-except
            reraise(SchedulingError, SchedulingError(
                "Couldn't apply scheduled task {0.name}: {exc}".format(
                    entry, exc=exc)), sys.exc_info()[2])
        finally:
            self._tasks_since_sync += 1
            if self.should_sync():
                self._do_sync()

    def send_task(self, *args, **kwargs):
        return self.app.send_task(*args, **kwargs)

    def setup_schedule(self):
        self.install_default_entries(self.data)
        self.merge_inplace(self.app.conf.beat_schedule)

    def _do_sync(self):
        try:
            debug('beat: Synchronizing schedule...')
            self.sync()
        finally:
            self._last_sync = time.monotonic()
            self._tasks_since_sync = 0

    def sync(self):
        pass



```
- celery的scheduler会把所有待执行的task封装对应的三元数组`(timestamps,priority,task)`,存到*self._heap*里面.然后会启动一个server,不断去调用*tick*方法。*tick*方法主要是从task-heap中获取到堆root节点，即为最近将要执行的task.并返回执行时间戳，作为下次调用*tick*的时间。
- 当有时间戳相同的情况下,会再比较优先级**priority**,同时如果是相同的任务,会再新生成一个task(`next_entry = self.reserve(entry)`),push到heap里面去.


### asyncio.event-loop
除了celery,python中asyncio.event-loop用来存放的延迟任务的优先队列也是一个最小堆的结构,具体可以看[python-event-loop](../../aysnc_/eventloop-futures.md)

